library(caret)
library(tabplot)
setwd("/Users/bear/Studies/Harvard/AML/hw3")
train = read.csv("train_data.csv")
sprintf("Train dataset has: %s rows and %s columns",nrow(train),ncol(train))
datatypes = data.frame(types=sapply(train,class))
ggplot(datatypes, aes(types,fill=types)) + geom_bar()
zz=zz[,-subject.G]
train = read.csv("train_data.csv")
test = read.csv("test_data.csv")
all = bind_rows(train[,1:669] , test)
all = all %>% mutate(subject=as.factor(subject), phase=as.factor(phase))
for (i in c(1:222)){
all[[paste0("ed",i)]] <- sqrt(all[[paste0("x",i)]] ^2 +
all[[paste0("y",i)]] ^2 +
all[[paste0("z",i)]]^2)
all[[paste0("md",i)]] <- abs(all[[paste0("x",i)]]) +
abs(all[[paste0("y",i)]]) +
abs(all[[paste0("z",i)]])
# all[[paste0("ce",i)]] <- (all[[paste0("x",i)]] +
#                           all[[paste0("y",i)]] +
#                           all[[paste0("z",i)]]) /3
}
#phase subject state
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep="."))
) %>% dummy.data.frame(sep=".")
#Remove 0 variance variables
#xx = xx[, -grep("x|y|z", colnames(xx))]
#xx = cbind(xx,pr.all$x[,1:10])
zz=xx[,-sapply(xx,var)!=0]
zz=zz[,-subject.G]
names(zz)
names(zz)[999:ncol(zz)]
zz=zz[,-c(subject.G)]
zz=zz[,-566]
zz=scale(zz)
train.mod = zz[1:4584,]
test.mod = zz[4585:nrow(zz),]
#fit psoutcome as the pred prob
dtrain = xgb.DMatrix(data = as.matrix(train.mod[,-ncol(train.mod)]), label = train$output)
library(knitr)
library(ggplot2)
library(dplyr)
library(dummies)
library(boot)
library(ROCR)
library(randomForest)
library(tidyr)
library(caret)
for (i in c(1:222)){
all[[paste0("ed",i)]] <- sqrt(all[[paste0("x",i)]] ^2 +
all[[paste0("y",i)]] ^2 +
all[[paste0("z",i)]]^2)
all[[paste0("md",i)]] <- abs(all[[paste0("x",i)]]) +
abs(all[[paste0("y",i)]]) +
abs(all[[paste0("z",i)]])
# all[[paste0("ce",i)]] <- (all[[paste0("x",i)]] +
#                           all[[paste0("y",i)]] +
#                           all[[paste0("z",i)]]) /3
}
#phase subject state
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep="."))
) %>% dummy.data.frame(sep=".")
#Remove 0 variance variables
#xx = xx[, -grep("x|y|z", colnames(xx))]
#xx = cbind(xx,pr.all$x[,1:10])
zz=xx[,-sapply(xx,var)!=0]
zz=zz[,-566]
zz=scale(zz)
train.mod = zz[1:4584,]
test.mod = zz[4585:nrow(zz),]
#fit psoutcome as the pred prob
dtrain = xgb.DMatrix(data = as.matrix(train.mod[,-ncol(train.mod)]), label = train$output)
library(xgboost)
#fit psoutcome as the pred prob
dtrain = xgb.DMatrix(data = as.matrix(train.mod[,-ncol(train.mod)]), label = train$output)
dtest = xgb.DMatrix(data = as.matrix(zz))
watchlist=list(train=dtrain,test=dtest)
#using optimised hyperparameters
bst = xgb.train(data=dtrain, nround=250,sub_sample = 0.9, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.01,min_child_weight=10, colsampleby_tree=.5, gamma=.1,max_depth=9)
train.mod = zz[1:4584,]
test.mod = zz[4585:nrow(zz),]
#fit psoutcome as the pred prob
dtrain = xgb.DMatrix(data = as.matrix(train.mod[,-ncol(train.mod)]), label = train$output)
dtest = xgb.DMatrix(data = as.matrix(zz))
watchlist=list(train=dtrain,test=dtest)
#using optimised hyperparameters
bst = xgb.train(data=dtrain, nround=250,sub_sample = 0.9, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.01,min_child_weight=10, colsampleby_tree=.5, gamma=.1,max_depth=9)
train$output
summary(train$output)
dtest = xgb.DMatrix(data = as.matrix(zz))
watchlist=list(train=dtrain,test=dtest)
bst = xgb.train(data=dtrain, nround=250,sub_sample = 0.9, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.01,min_child_weight=10, colsampleby_tree=.5, gamma=.1,max_depth=9)
xs = all[,grep("^x",names(all))]
names(xs)
all = bind_rows(train[,1:669] , test)
all = all %>% mutate(subject=as.factor(subject), phase=as.factor(phase))
for (i in c(1:222)){
all[[paste0("ed",i)]] <- sqrt(all[[paste0("x",i)]] ^2 +
all[[paste0("y",i)]] ^2 +
all[[paste0("z",i)]]^2)
all[[paste0("md",i)]] <- abs(all[[paste0("x",i)]]) +
abs(all[[paste0("y",i)]]) +
abs(all[[paste0("z",i)]])
# all[[paste0("ce",i)]] <- (all[[paste0("x",i)]] +
#                           all[[paste0("y",i)]] +
#                           all[[paste0("z",i)]]) /3
}
#phase subject state
xs = all[,grep("^x",names(all))]
ys = all[,grep("^y",names(all))]
zs = all[,grep("^z",names(all))]
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
meanx = mean(xs),
miny = min(ys),
maxy = max(ys),
meany = mean(ys),
minz = min(xz),
maxz = max(xz),
meanz = mean(xz)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz) %>%
mutate (
alenx = abs(lenx),
ahgtx = abs(hgtx),
awdth = abs(wdth)) %>%
mutate(
area = alenx * aghtx * awdth,
centroid = (meanx + meany + meanz) / 3
) %>%
dummy.data.frame(sep=".")
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
meanx = mean(xs),
miny = min(ys),
maxy = max(ys),
meany = mean(ys),
minz = min(zs),
maxz = max(zs),
meanz = mean(zs)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz) %>%
mutate (
alenx = abs(lenx),
ahgtx = abs(hgtx),
awdth = abs(wdth)) %>%
mutate(
area = alenx * aghtx * awdth,
centroid = (meanx + meany + meanz) / 3
) %>%
dummy.data.frame(sep=".")
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
meanx = mean(xs),
miny = min(ys),
maxy = max(ys),
meany = mean(ys),
minz = min(zs),
maxz = max(zs),
meanz = mean(zs)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz) %>%
mutate (
alenx = abs(lenx),
ahgtx = abs(hgtx),
awdth = abs(wdth)) %>%
mutate(
area = alenx * ahgtx * awdth,
centroid = (meanx + meany + meanz) / 3
) %>%
dummy.data.frame(sep=".")
zz=xx[,-sapply(xx,var)!=0]
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
meanx = mean(xs),
miny = min(ys),
maxy = max(ys),
meany = mean(ys),
minz = min(zs),
maxz = max(zs),
meanz = mean(zs)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz) %>%
mutate (
alenx = abs(lenx),
ahgtx = abs(hgtx),
awdth = abs(wdth)) %>%
mutate(
area = alenx * ahgtx * awdth #,
#  centroid = (meanx + meany + meanz) / 3
) %>%
dummy.data.frame(sep=".")
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
meanx = mean(xs),
miny = min(ys),
maxy = max(ys),
meany = mean(ys),
minz = min(zs),
maxz = max(zs),
meanz = mean(zs)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz)
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
meanx = mean(xs),
miny = min(ys),
maxy = max(ys),
meany = mean(ys),
minz = min(zs),
maxz = max(zs),
meanz = mean(zs)
)
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
meanx = mean(xs))
min(xs)
mean(xs)
summary(xs)
xs[1:10]
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
miny = min(ys),
maxy = max(ys),
minz = min(zs),
maxz = max(zs)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz)
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
miny = min(ys),
maxy = max(ys),
minz = min(zs),
maxz = max(zs)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz) %>%
mutate (
alenx = abs(lenx),
ahgtx = abs(hgtx),
awdth = abs(wdth)) %>%
mutate(
area = alenx * ahgtx * awdth #,
#  centroid = (meanx + meany + meanz) / 3
) %>%
dummy.data.frame(sep=".")
zz=xx[,-sapply(xx,var)!=0]
zz=zz[,-566]
zz=scale(zz)
train.mod = zz[1:4584,]
test.mod = zz[4585:nrow(zz),]
x
train = read.csv("train_data.csv")
test = read.csv("test_data.csv")
all = bind_rows(train[,1:669] , test)
all = all %>% mutate(subject=as.factor(subject), phase=as.factor(phase))
for (i in c(1:222)){
all[[paste0("ed",i)]] <- sqrt(all[[paste0("x",i)]] ^2 +
all[[paste0("y",i)]] ^2 +
all[[paste0("z",i)]]^2)
all[[paste0("md",i)]] <- abs(all[[paste0("x",i)]]) +
abs(all[[paste0("y",i)]]) +
abs(all[[paste0("z",i)]])
# all[[paste0("ce",i)]] <- (all[[paste0("x",i)]] +
#                           all[[paste0("y",i)]] +
#                           all[[paste0("z",i)]]) /3
}
#phase subject state
xs = all[,grep("^x",names(all))]
ys = all[,grep("^y",names(all))]
zs = all[,grep("^z",names(all))]
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
miny = min(ys),
maxy = max(ys),
minz = min(zs),
maxz = max(zs)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz) %>%
mutate (
alenx = abs(lenx),
ahgtx = abs(hgtx),
awdth = abs(wdth)) %>%
mutate(
area = alenx * ahgtx * awdth #,
#  centroid = (meanx + meany + meanz) / 3
) %>%
dummy.data.frame(sep=".")
library(knitr)
library(ggplot2)
library(dplyr)
library(dummies)
library(boot)
library(ROCR)
library(randomForest)
library(tidyr)
library(caret)
library(tabplot)
setwd("/Users/bear/Studies/Harvard/AML/hw3")
train = read.csv("train_data.csv")
test = read.csv("test_data.csv")
all = bind_rows(train[,1:669] , test)
all = all %>% mutate(subject=as.factor(subject), phase=as.factor(phase))
for (i in c(1:222)){
all[[paste0("ed",i)]] <- sqrt(all[[paste0("x",i)]] ^2 +
all[[paste0("y",i)]] ^2 +
all[[paste0("z",i)]]^2)
all[[paste0("md",i)]] <- abs(all[[paste0("x",i)]]) +
abs(all[[paste0("y",i)]]) +
abs(all[[paste0("z",i)]])
# all[[paste0("ce",i)]] <- (all[[paste0("x",i)]] +
#                           all[[paste0("y",i)]] +
#                           all[[paste0("z",i)]]) /3
}
#phase subject state
xs = all[,grep("^x",names(all))]
ys = all[,grep("^y",names(all))]
zs = all[,grep("^z",names(all))]
xx = all %>% mutate(phsust=as.factor(paste0(phase,subject,state, sep=".")),
phsu=as.factor(paste0(phase,subject, sep=".")),
phst=as.factor(paste0(phase,state, sep=".")),
sust=as.factor(paste0(subject,state, sep=".")),
minx = min(xs),
maxx = max(xs),
miny = min(ys),
maxy = max(ys),
minz = min(zs),
maxz = max(zs)
) %>%
mutate (
lenx = maxx - minx,
hgtx = maxy - miny,
wdth = maxz - minz) %>%
mutate (
alenx = abs(lenx),
ahgtx = abs(hgtx),
awdth = abs(wdth)) %>%
mutate(
area = alenx * ahgtx * awdth #,
#  centroid = (meanx + meany + meanz) / 3
) %>%
dummy.data.frame(sep=".")
train.mod = zz[1:4584,]
test.mod = zz[4585:nrow(zz),]
set.seed(321)
indexes = sample(1:nrow(train.mod), size=0.8*nrow(train.mod))
train.train = xgb.DMatrix(data = as.matrix(train.mod[indexes,]), label = train$output[indexes])
train.test = xgb.DMatrix(data = as.matrix(train.mod[-indexes,]), label = train$output[-indexes])
watchlist = list(train=train.train, test=train.test)
bst = xgb.train(data=dtrain, nround=250,sub_sample = 1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=10)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
zz=xx[,-sapply(xx,var)!=0]
zz=zz[,-566]
train.mod = zz[1:4584,]
test.mod = zz[4585:nrow(zz),]
set.seed(321)
indexes = sample(1:nrow(train.mod), size=0.8*nrow(train.mod))
train.train = xgb.DMatrix(data = as.matrix(train.mod[indexes,]), label = train$output[indexes])
train.test = xgb.DMatrix(data = as.matrix(train.mod[-indexes,]), label = train$output[-indexes])
watchlist = list(train=train.train, test=train.test)
bst = xgb.train(data=dtrain, nround=250,sub_sample = 1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=10)
library(xgboost)
train.train = xgb.DMatrix(data = as.matrix(train.mod[indexes,]), label = train$output[indexes])
train.test = xgb.DMatrix(data = as.matrix(train.mod[-indexes,]), label = train$output[-indexes])
watchlist = list(train=train.train, test=train.test)
bst = xgb.train(data=dtrain, nround=250,sub_sample = 1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=10)
bst = xgb.train(data=train.train, nround=250,sub_sample = 1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=10)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = 1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=8)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = 1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=12)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = 1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=6)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = 1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
library(DiagrammeR)
xgb.plot.tree(model=bst)
importance_matrix = xgb.importance(model=bst)
xgb.plot.importance(importance_matrix = importance_matrix)
importance_matrix
train.test[,c(1169,1240,568,1151,1152)]
names(train.test)[c(1169,1240,568,1151,1152)]
colnames(train.test)[c(1169,1240,568,1151,1152)]
bst = xgb.train(data=train.train, nround=100,sub_sample = .5, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=5, colsampleby_tree=.2, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=1, colsampleby_tree=.2, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=1, colsampleby_tree=.6, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=150,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.05,min_child_weight=1, colsampleby_tree=.6, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=150,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.08,min_child_weight=1, colsampleby_tree=.6, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=1, colsampleby_tree=.6, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=200,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=1, colsampleby_tree=.6, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=100,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=1, colsampleby_tree=.6, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
bst = xgb.train(data=train.train, nround=75,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=1, colsampleby_tree=.6, gamma=.1,max_depth=9)
ggplot(bst$evaluation_log, aes(iter)) +
geom_line(aes(y = train_error, colour = "Training err")) +
geom_line(aes(y = test_error, colour = "Test err"))
dtrain = xgb.DMatrix(data = as.matrix(train.mod), label = train$output)
dtest = xgb.DMatrix(data = as.matrix(test.mod))
bst = xgb.train(data=dtrain, nround=75,sub_sample = .1, watchlist = watchlist, eval.metric ="error", eval.metric="auc", objective = "binary:logistic",eta=.1,min_child_weight=1, colsampleby_tree=.6, gamma=.1,max_depth=9)
pred = predict(bst, dtest)
final = data.frame(id=1:length(pred)-1, output=pred)
write.csv(final,file="try9.csv",row.names=FALSE)
